{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoreload\n",
    "\n",
    "Autoreload allows the notebook to dynamically load code: if we update some helper functions *outside* of the notebook, we do not need to reload the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All auxiliary code is in ../src\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As first thing we imported all necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "races = pd.read_csv('../dataset/races.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diamo una prima occhiata ai valori mancanti nulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[races.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe with only race attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclist_races_columns = ['position', 'cyclist', 'cyclist_age', 'cyclist_team', 'delta', 'date']\n",
    "races_columns = [col for col in races.columns if col not in cyclist_races_columns]\n",
    "races_data = races.drop_duplicates(subset=races_columns)[races_columns].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come prima cosa distingurei i valori delle singole corse con i dati relativi ai ciclisti della corsa per cercare di rimuovere ridondanza dei dati che potrebbe falsare le nostre distribuzioni a favore dei valori delle corse con più ciclisti -> separiamo in due tabelle normalizzate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "for feature in races_data.select_dtypes(include=\"number\").columns: \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Istogramma per races_data\n",
    "    sns.histplot(races_data[feature], ax=axes[0])\n",
    "    axes[0].set_title(f'Histogram of {feature} in races_data')\n",
    "    axes[0].set_xlabel(feature)\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "\n",
    "    # Istogramma per races\n",
    "    sns.histplot(races[feature], ax=axes[1])\n",
    "    axes[1].set_title(f'Histogram of {feature} in races')\n",
    "    axes[1].set_xlabel(feature)\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "\n",
    "    plt.tight_layout()  # Per evitare sovrapposizioni\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats on attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def stats(column, box=False):\n",
    "    print(f\"Description of attribute '{column.name}':\")\n",
    "    display(column.describe())\n",
    "    print(\"\\nUnique values:\")\n",
    "    print(column.unique())\n",
    "    print(f\"\\nNumber of null values: {column.isnull().sum()}\")\n",
    "    mv = column.isna().sum()\n",
    "    nrec = races.shape[0]\n",
    "    per=mv*100/nrec\n",
    "    print(f\"\\n{mv} null values over {nrec} records - ({per:.2f}%)\")\n",
    "    print(\"\\nTop 5 common value:\" + \"\\n\"+str(column.value_counts().head()))\n",
    "    \n",
    "   \n",
    "    if box:\n",
    "        boxplot_dict = plt.boxplot(column[~np.isnan(column)])\n",
    "        #recover outliers from boxplot\n",
    "        outliers = [flier.get_ydata() for flier in boxplot_dict['fliers']]\n",
    "        #get the list of outliers without duplicates\n",
    "        outliers_values = list({value for sublist in outliers for value in sublist})\n",
    "        print(\"\\nOutliers:\", outliers_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci accorgiamo che il 13-enne è un errore perchè le gare ammettono maggiorenni. Il 56-enne è un outliers. Controllare i valori al di fuori della coda del boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"cyclist_age\"], box=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"_url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"points\"], box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"uci_points\"], box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"length\"], box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"climb_total\"], box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"uci_points\"], box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"profile\"], box=True) # ? occhio a media su categorico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"startlist_quality\"], box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"average_temperature\"], box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"position\"]) # ordinale numerico come gestirlo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"cyclist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"cyclist_age\"], box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"is_tarmac\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"is_cobbled\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"is_gravel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"cyclist_team\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"delta\"], box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[races[\"_url\"].str.startswith('vuelta-a-espana/1996/stage')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il box plot relativo a questo attributo, mostrava la presenza di diversi outliers, in particolare ci siamo focalizzati su due di questi, con valori rispettivamente di 13 e 56."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[(races['cyclist_age'] == 13) | (races['cyclist_age'] == 56)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerato che il dataset \"cyclists\" riporta l'anno di nascita del ciclista \"planem-stanev\" (1988), e che l'unica gara a cui ha partecipato si è tenuta nel 2001, di conseguenza l'età (13) che presentava in quella gara coincide con quella indicata nel dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di seguito verifichiamo che ci sia consistenza tra l'anno di nascita indicata nel dataset \"cyclists\" e l'età durante la partecipazione alla gara indicata nel dataset \"races\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for age consistency detection between the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df = pd.read_csv('../dataset/cyclists.csv')\n",
    "cyclists_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get unique cyclists from races dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_races = races['cyclist'].unique()\n",
    "cyclists_races_count = len(cyclists_races)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get unique cyclists from cyclists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_uniques = cyclists_df['_url'].unique()\n",
    "cyclists_unique_count = len(cyclists_uniques)\n",
    "if (len(cyclists_df['_url']) == cyclists_unique_count):\n",
    "    print(\"Correctly each cyclist url appears only one time in the cyclists dataset as row\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare number of cyclists\n",
    "We can see that races dataset contains 39 more cyclist than cyclists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of unique cyclists in the cyclists dataset: {cyclists_unique_count}\\\n",
    "      \\nNumber of unique cyclists in the races dataset: {cyclists_races_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare cyclists\n",
    "We show the list of different cyclists between the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.setxor1d(cyclists_uniques, cyclists_races)\n",
    "print(f\"{len(diff)} different cyclists between the two datasets: {diff}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll compare only the age of cyclists that appear in both datasets.\n",
    "First we'll need to transform the date field of the races datasets, to make comparison easier. We'll transform from object to pandas datetime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(races['date'].dtype)\n",
    "races['date'] = pd.to_datetime(races['date']).dt.floor('d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For what concern the field birth_year in the cyclists dataset, we'll transform from float to int, because here we have only the year information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cyclists_df['birth_year'].dtype)\n",
    "#by using Int64 we don't get error due to the presence of Nan\n",
    "cyclists_df['birth_year'] = cyclists_df['birth_year'].astype('Int64')\n",
    "\n",
    "print(cyclists_df['birth_year'].head())\n",
    "print(cyclists_df['birth_year'].dtype)  \n",
    "\n",
    "# cyclists_df['birth_year'] = pd.to_datetime(cyclists_df['birth_year']).dt.date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For what concern cyclist_age field in the races dataset, we'll transform from float to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(races['cyclist_age'].dtype)\n",
    "races['cyclist_age'] = races['cyclist_age'].astype('Int64')\n",
    "\n",
    "print(races['cyclist_age'].head())\n",
    "print(races['cyclist_age'].dtype)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging datasets on the same cyclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(cyclists_df, races, left_on='_url', right_on='cyclist', how='inner')\n",
    "print(merged_df.shape)\n",
    "print(merged_df[['birth_year', 'cyclist_age', 'date']])\n",
    "# write in a temporary file for offline checking\n",
    "merged_df.to_csv('../../dataset/merged_df_temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking age consistency\n",
    "We do this by calculating the expected age at the race moment, and then comparing this age with the one indicated in the races dataset.\n",
    "We do this step for each row, so for each cyclist and all the stages of all races in which he participated.\n",
    "\n",
    "If even only one among these fields: birth_year, cyclist_age, date, is not valued, we'll skip the corresponding row.\n",
    "\n",
    "As we can see, we get a truly consistency between the ages indicated into the two dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = merged_df.dropna(subset=['birth_year', 'date', 'cyclist_age']).copy()\n",
    "\n",
    "# we regard only on race year\n",
    "df_filtered['date'] = df_filtered['date'].dt.year\n",
    "\n",
    "df_filtered['expected_age'] = df_filtered['date'] - df_filtered['birth_year']\n",
    "\n",
    "df_filtered['consistent_age'] = (df_filtered['cyclist_age'] == df_filtered['expected_age'])\n",
    "\n",
    "df_filtered['consistent_age'].all()\n",
    "\n",
    "df_filtered.to_csv('../../dataset/df_for_age_consistency.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alcuni nomi di gare differiscono per singoli caratteri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names=races['name'].unique()\n",
    "sorted(unique_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alcuni delta negativi\n",
    "- Primi classificati con delta diverso da 0 \n",
    "- Inconsistenza tra la semantica della colonna e i valori effettivamente indicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = races[races['delta'] < 0]['delta']\n",
    "len(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[(races['position'] == 1) & (races['delta'] != 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is_gravel, is_tarmac, is_cobbled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Righe in cui tutti e 3 sono settati su false. Vuol dire che è un missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[(races['is_gravel'] == False) & (races['is_tarmac'] == False) & (races['is_cobbled'] == False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alcune di queste colonne presentano tutti valori false/true -> potrebbe essere inutile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[(races['is_gravel'] == True) | (races['is_cobbled'] == True)].shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa feature presenta circa il 95% di valori nulli, dunque non determinante ai fini delle nostre analisi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values = len(races[races['average_temperature'].isna()])\n",
    "print((null_values/races.shape[0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points e UCI_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spiegare differenza\n",
    "- Dire che uci_points presenta la maggior parte di valori nulli, e quindi può essere droppato\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come prima cosa distingurei i valori delle singole corse con i dati relativi ai ciclisti della corsa per cercare di rimuovere ridondanza dei dati che potrebbe falsare le nostre distribuzioni a favore dei valori delle corse con più ciclisti -> separiamo in due tabelle normalizzate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the frequence of each distinct _url\n",
    "values_count = races_data['_url'].value_counts()\n",
    "# if a race has a frequency > 1 then this race may represent an inconsistency between the race's attributes\n",
    "inconsistent_urls = values_count[values_count > 1]\n",
    "len(inconsistent_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = races[races['length'] <= 10000]\n",
    "temp['_url'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spiegare che abbiamo trovato dalla distribuzione che molte gare hanno una lunghezza breve, e quindi abbiamo cercato di verificare se ci fosse un errore di scala, oppure se ci sono effettivamente gare/tappe di lunghezza molto breve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo riscontrato che le gare di lunghezza più breve, contengono prologue nell'url (e forse stage-1), e ottenuto conferma che esista effettivamente la tappa iniziale chiamata prologo, di una lunghezza dai 1000 ai 10000 circa metri.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_subset = races[races['_url'].str.contains(\"prologue\")][['_url', 'length']].drop_duplicates(subset=['_url'])\n",
    "unique_subset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlazione attributi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_races_data = races_data.select_dtypes(include=\"number\")\n",
    "numeric_races_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La correlazione tra points e uci_points è molto alta, facciamo uno scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.scatterplot(data=races_data, x=\"points\", y=\"uci_points\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
