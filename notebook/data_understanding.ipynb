{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoreload\n",
    "\n",
    "Autoreload allows the notebook to dynamically load code: if we update some helper functions *outside* of the notebook, we do not need to reload the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All auxiliary code is in ../src\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As first thing we imported all the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sbn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "races = pd.read_csv('../dataset/races.csv', sep=\",\")\n",
    "cyclists = pd.read_csv('../dataset/cyclists.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, each data object of the _races_ dataset represents a placement of a cyclist in a particular cycling competition.\n",
    "Let's see which column types are automatically inferred by Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: In questa parte stiamo selezionando le colonne in cui c'è almeno un missing value... fondamentalmente da questa visualizzazione non si capisce nulla quindi la modificherei integramente. \n",
    "Diamo una prima occhiata ai valori mancanti nulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[races.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram plotting for numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plot for categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats on attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom procedure that produces some basic statistics on a single feature of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#'box' parameter enables the boxplot representation\n",
    "def stats(column, box=False):\n",
    "    print(f\"Description of attribute '{column.name}':\")\n",
    "    display(column.describe())\n",
    "    print(\"\\nUnique values:\")\n",
    "    print(column.unique())\n",
    "    mv = column.isna().sum()\n",
    "    nrec = races.shape[0]\n",
    "    per=mv*100/nrec\n",
    "    print(f\"\\nNull values: {mv} over {nrec} records - ({per:.2f}%)\")\n",
    "    print(\"\\nTop 5 common value:\" + \"\\n\"+str(column.value_counts().head()))\n",
    "    \n",
    "   \n",
    "    if box:\n",
    "        boxplot_dict = plt.boxplot(column[~np.isnan(column)])\n",
    "        #recover outliers from boxplot\n",
    "        outliers = [flier.get_ydata() for flier in boxplot_dict['fliers']]\n",
    "        #get the list of outliers without duplicates\n",
    "        outliers_values = list({value for sublist in outliers for value in sublist})\n",
    "        print(\"\\nOutliers:\", outliers_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Age_ is a continuous attribute. The float64 column can be cast to int as the unique values are not decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notNa_column=races['cyclist_age'].dropna(axis=0, inplace=False)\n",
    "#type convertion works only without NaN values\n",
    "np.all(notNa_column==notNa_column.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"cyclist_age\"], box=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median cyclist age is 28. The boxplot marks as outliers all the placements of cyclists older than 38. We can notice two extreme outliers regarding at the ages of 13 and 56. These values can be considered as simple outliers or as errors; further investigations on that will be provided in the next sections.\n",
    "\n",
    "The presence of 113 missing values can be mitigated using the information in the \"cyclists\" dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _url_ is a categorical feature of type string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"_url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __url_ feature can be considered as an identifier of the race event. The url is in the form _eventName/year/stagename_.\n",
    "The fact that there are many rows with URLs starting with _Tour de France_ or _Giro d'Italia_ is related to the importance of these two events in the cycling world. These two races typically have a lot of participants and are composed of more than one stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values and, as expected and already explained, the most common values are the names of the more prestigious races."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points - Uci_Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Points_ and _uci points_ are numeric continuous attributes. Their type can be cast to int since there are no decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notNa_column=races['points'].dropna(axis=0, inplace=False)\n",
    "#type convertion works only without NaN values\n",
    "np.all(notNa_column==notNa_column.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notNa_column=races['uci_points'].dropna(axis=0, inplace=False)\n",
    "#type convertion works only without NaN values\n",
    "np.all(notNa_column==notNa_column.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"points\"], box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"uci_points\"], box=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _length_ is a numeric continuous attribute representing the lenght of the race event. Its type can be cast to int since there are no decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notNa_column=races['length'].dropna(axis=0, inplace=False)\n",
    "#type convertion works only without NaN values\n",
    "np.all(notNa_column==notNa_column.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Controllare perchè il cast ad int non produce lo stesso risultato..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"length\"], box=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climb total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Climb total_ is a numeric continuous attribute representing the number of metres climbed during the race event. Its type can be cast to int since there are no decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type convertion works only without NaN values\n",
    "res = np.all(races['climb_total'] == races['climb_total'].astype('Int64'))\n",
    "print(res)\n",
    "if res:\n",
    "    races['climb_total'] = races['climb_total'].astype('Int64')\n",
    "\n",
    "races['climb_total'].dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"climb_total\"], box=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _profile_ feature is a categorical ordinal attribute. It has a range from 1 to 5 and it represents the difficulty of that race event. Its type can be cast to int since there are no decimals. <br>\n",
    "**TODO**: Controllare se può andare bene o meno fare la media, boxplot ecc di un attributo categorico!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notNa_column=races['profile'].dropna(axis=0, inplace=False)\n",
    "#type convertion works only without NaN values\n",
    "np.all(notNa_column==notNa_column.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"profile\"], box=True) # ? occhio a media su categorico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Startlist quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _startlist quality_ feature is a numeric continuous attribute. It's a number that summarizes the overall competitiviness of the cyclists participating to a race event. Its type can be cast to int since there are no decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notNa_column=races['startlist_quality'].dropna(axis=0, inplace=False)\n",
    "#type convertion works only without NaN values\n",
    "np.all(notNa_column==notNa_column.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"startlist_quality\"], box=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Temperature\n",
    "The _average temperature_ feature is a numeric continous attribute. It describes the average temperature recorded during that race. Its type can be cast to int since there are no decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notNa_column=races['average_temperature'].dropna(axis=0, inplace=False)\n",
    "#type convertion works only without NaN values\n",
    "np.all(notNa_column==notNa_column.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"average_temperature\"], box=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date\n",
    "**TODO** La data è un attributo continuo o categorico? <br>\n",
    "The _date_ feature is .................... It represents the timestamp of the race start. For our purposes the time is irrelevant, so the column can be cast to 'date'. <br>\n",
    "**TODO** Inserire lo snippet per estrarre solamente la data scarta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertion of the object column to datetime64 (There are no missing values)\n",
    "races['date']=pd.to_datetime(races['date']).dt.floor('d')\n",
    "print(races['date'].dtype)\n",
    "# #Extraction of the date field\n",
    "# races['date'] = races['date'].dt.date\n",
    "# print(races['date'].dtype)\n",
    "# print(races['date'][1].year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position\n",
    "The position is a numeric ordinal attribute. It represents the finish position of the cyclist in the race event described by that row. Its type can be cast to int since there are no decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notNa_column=races['position'].dropna(axis=0, inplace=False)\n",
    "#type convertion works only without NaN values\n",
    "np.all(notNa_column==notNa_column.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"position\"]) # ordinale numerico come gestirlo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the listing of the unique values we can see that the maximum number of participants to a race event in the dataset is 209."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyclist\n",
    "The cyclist is a categorical attribute that represents the reference to the cyclists that has obtained the placement. Its type is a string in a format _name-surname_.\n",
    "\n",
    "**TODO** Analisi sui ciclisti che hanno partecipato alle varie gare tipo i ciclisti più presenti nel dataset, le nazionalità più rappresentate, i team. Serve fare la join con l'altro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"cyclist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[races['cyclist']=='matteo-tosatto'][['_url', 'date']].sort_values(by='date', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is_Surface TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"is_tarmac\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"is_cobbled\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"is_gravel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyclist Team TODO\n",
    "statistiche su moda, team con più ciclisti ecc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"cyclist_team\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(races[\"delta\"], box=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Perchè abbiamo messo questo codice sotto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[races[\"_url\"].str.startswith('vuelta-a-espana/1996/stage')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box plot for this attribute showed the presence of several outliers, particularly those ages over 38. Our analysis focused on two of them, with values of 13 and 56 respectively, which are very different from the other values. In particular, we tried to investigate whether these values could be erroneous or legitimate outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[(races['cyclist_age'] == 13) | (races['cyclist_age'] == 56)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerato che il dataset \"cyclists\" riporta l'anno di nascita del ciclista \"planem-stanev\" (1988), e che l'unica gara a cui ha partecipato si è tenuta nel 2001, di conseguenza l'età (13) che presentava in quella gara coincide con quella indicata nel dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di seguito verifichiamo che ci sia consistenza tra l'anno di nascita indicata nel dataset \"cyclists\" e l'età durante la partecipazione alla gara indicata nel dataset \"races\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for age consistency detection between the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_df = pd.read_csv('../dataset/cyclists.csv')\n",
    "cyclists_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get unique cyclists from races dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_races = races['cyclist'].unique()\n",
    "cyclists_races_count = len(cyclists_races)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get unique cyclists from cyclists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclists_uniques = cyclists_df['_url'].unique()\n",
    "cyclists_unique_count = len(cyclists_uniques)\n",
    "if (len(cyclists_df['_url']) == cyclists_unique_count):\n",
    "    print(\"Correctly each cyclist url appears only one time in the cyclists dataset as row\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare number of cyclists\n",
    "We can see that races dataset contains 39 more cyclist than cyclists dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of unique cyclists in the cyclists dataset: {cyclists_unique_count}\\\n",
    "      \\nNumber of unique cyclists in the races dataset: {cyclists_races_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare cyclists\n",
    "We show the list of different cyclists between the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.setxor1d(cyclists_uniques, cyclists_races)\n",
    "print(f\"{len(diff)} different cyclists between the two datasets: {diff}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For what concern the field birth_year in the cyclists dataset, we'll transform from float to int, because here we have only the year information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cyclists_df['birth_year'].dtype)\n",
    "#by using Int64 we don't get error due to the presence of Nan\n",
    "cyclists_df['birth_year'] = cyclists_df['birth_year'].astype('Int64')\n",
    "\n",
    "print(cyclists_df['birth_year'].head())\n",
    "print(cyclists_df['birth_year'].dtype)  \n",
    "\n",
    "# cyclists_df['birth_year'] = pd.to_datetime(cyclists_df['birth_year']).dt.date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For what concern cyclist_age field in the races dataset, we'll transform from float to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(races['cyclist_age'].dtype)\n",
    "races['cyclist_age'] = races['cyclist_age'].astype('Int64')\n",
    "\n",
    "print(races['cyclist_age'].head())\n",
    "print(races['cyclist_age'].dtype)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging datasets on the same cyclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(cyclists_df, races, left_on='_url', right_on='cyclist', how='inner')\n",
    "print(merged_df.shape)\n",
    "print(merged_df[['birth_year', 'cyclist_age', 'date']])\n",
    "# write in a temporary file for offline checking\n",
    "merged_df.to_csv('../../dataset/merged_df_temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking age consistency\n",
    "We do this by calculating the expected age at the race moment, and then comparing this age with the one indicated in the races dataset.\n",
    "We do this step for each row, so for each cyclist and all the stages of all races in which he participated.\n",
    "\n",
    "If even only one among these fields: birth_year, cyclist_age, date, is not valued, we'll skip the corresponding row.\n",
    "\n",
    "As we can see, we get a truly consistency between the ages indicated into the two dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = merged_df.dropna(subset=['birth_year', 'date', 'cyclist_age']).copy()\n",
    "\n",
    "# we regard only on race year\n",
    "df_filtered['date'] = df_filtered['date'].dt.year\n",
    "\n",
    "df_filtered['expected_age'] = df_filtered['date'] - df_filtered['birth_year']\n",
    "\n",
    "df_filtered['consistent_age'] = (df_filtered['cyclist_age'] == df_filtered['expected_age'])\n",
    "\n",
    "print(df_filtered['consistent_age'].all())\n",
    "\n",
    "df_filtered.to_csv('../../dataset/df_for_age_consistency.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the ‘cyclists’ dataset shows the year of birth of the cyclist ‘planem-stanev’ (1988), and that the only race he took part in was held in 2001, consequently the age (13) he was in that race matches with the age in the 'races' dataset. So we are not able to affirm that the age 13, which seems an error because typically it's required to be of legal age to take part in a professional cycling race, is actually an error to be discarded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script checks the consistency between the age contained in the row of the 'races' dataset and the real cyclist age computed using the birth year from the dataset 'cyclists'.\n",
    "**TODO**  SCRIVERE ALGORITMO CHE CONTROLLA CONSISTENZA ETA TRA TUTTI I CICLISTI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see by sorting all the unique values of the column name, there are some race names that may refer to the same race event. In fact there are only few differences in those name such as the presence of:\n",
    "- accents ['Clásica Ciclista San Sebastian' vs 'Clásica Ciclista San Sebastián]\n",
    "- separating characters (- or /) ['Liège - Bastogne - Liège' vs 'Liège-Bastogne-Liège']\n",
    "- articles ['La Vuelta ciclista a España' vs 'Vuelta a España]\n",
    "Actually this is not a problem for our analysis. The starting part of the _url feature, which is the name of the race event, is correctly formatted for all of these \"mismatch\" situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names=races['name'].unique()\n",
    "sorted(unique_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Vedere correlazione con presenza di ME e maggiore startlist quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature should indicate the delay in seconds, of the cyclist represented in the row, in relation to the first classified in that race event.\n",
    "However, there are some negative delta values and, in addition, the first classifiers of some races may have a delta value different from zero.\n",
    "It seems that there is an inconsistency between the semantics of this column and the real values it contains. In fact a delay from the first classified should not be less than zero and the delay of the first classifier should be zero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = races[races['delta'] < 0]['delta']\n",
    "len(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[(races['position'] == 1) & (races['delta'] != 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is_gravel, is_tarmac, is_cobbled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the code cell below, the columns _is gravel_ and _is cobbled_ contain only False values. It means that they provide no information because all the records in the dataset have the same value for these attributes (Entropy=0).\n",
    "It seems that the 3 attributes representing the race surfaces were obtained by binarizing an original single categorical column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[(races['is_gravel'] == True) | (races['is_cobbled'] == True)].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the _is tarmac_ feature, most of the records have a true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per=(((races[races['is_tarmac'] == True].shape[0])*100)/len(races))\n",
    "print(f\"True values: {per:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also records where all the 3 features have a false value. This may be due to a missing value in the original categorical column before the binarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[(races['is_gravel'] == False) & (races['is_tarmac'] == False) & (races['is_cobbled'] == False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature has 95% of missing values, so it's not relevant for out analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per=(((len(races[races['average_temperature'].isna()]))*100)/len(races))\n",
    "print(f\"Missing values: {per:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Points e UCI_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI score in cycling is a ranking system used by the Union Cycliste Internationale (UCI) to determine the top cyclists and teams in the world. It is based on a points system where cyclists earn points for their performance in various races throughout the season. The UCI score is used to determine the World Champion, the UCI World Ranking, and the qualification for major cycling events like the Tour de France.\n",
    "\n",
    "Actually in this dataset the attributes 'uci_points' and 'points' are strictly related to a race event and not, as we would expect, to the placement of a cyclist in a particular race event. The fact that a race has two scores creates a sort of ambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[races['points'].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races[races['uci_points'].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the feature uci_points has a lot of missing values (>50% of the number of records). In particular all the races held before the 2001 do not have not this information. This may be due the introduction of this scoring system in the early 2000s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = pd.to_datetime(\"2001-1-1\")\n",
    "filtered=races[races['date'] <= cutoff_date]\n",
    "filtered=filtered.sort_values(by='date', ascending=True)\n",
    "filtered=filtered[filtered['uci_points'].notna()]\n",
    "#check if there are MV before 1/1/2001\n",
    "filtered.shape[0]==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the fact that, as shown in the correlation analysis section, 'uci_points' and 'points' are highly correlated and 'uci_points' have many missing values, we can decide to drop these feature and maintain only 'points'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe with only race attributes\n",
    "Each row of the dataset contains both information exclusively related to the cycling event and information strictly related to the placement of the cyclist analysed. In order to produce meaningful statistics, it might be useful to separate these different types of information. Indeed, the presence of redundant information may favour in the overall analysis those single 'cycling events' for which we have many related entries.\n",
    "**TODO**: RIMUOVERE <br>\n",
    "Come prima cosa distingurei i valori delle singole corse con i dati relativi ai ciclisti della corsa per cercare di rimuovere ridondanza dei dati che potrebbe falsare le nostre distribuzioni a favore dei valori delle corse con più ciclisti -> separiamo in due tabelle normalizzate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction of features related to the race and not to the placement\n",
    "cyclist_races_columns = ['position', 'cyclist', 'cyclist_age', 'cyclist_team', 'delta', 'date']\n",
    "races_columns = [col for col in races.columns if col not in cyclist_races_columns]\n",
    "\n",
    "#races_data will contain all the 'events' in the dataset with their specific information\n",
    "races_data = races.drop_duplicates(subset=races_columns)[races_columns].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, analysing the data distribution without considering the issue of redundancy in the rows can lead to different results.\n",
    "The histograms on the right-hand side part of the row are produced on the raw data, hence without grouping on the single race event, whereas  those on the left-hand side considers only the single race events. <br>\n",
    "**TODO**: Il # di bin in questi plot come è stato scelto? automaticamente? Penso che ci sia una differenza forse.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in races_data.select_dtypes(include=\"number\").columns: \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Istogramma per races_data\n",
    "    sbn.histplot(races_data[feature], ax=axes[0])\n",
    "    axes[0].set_title(f'Histogram of {feature} in races_data')\n",
    "    axes[0].set_xlabel(feature)\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "\n",
    "    # Istogramma per races\n",
    "    sbn.histplot(races[feature], ax=axes[1])\n",
    "    axes[1].set_title(f'Histogram of {feature} in races')\n",
    "    axes[1].set_xlabel(feature)\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "\n",
    "    plt.tight_layout()  # Per evitare sovrapposizioni\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no inconsistent information regarding a specific race event. An example of an anomalous situation is the case where two rows referring to the same race event have different values for a race-specific attribute such as length, avg_temperature, profile..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the frequence of each distinct _url\n",
    "values_count = races_data['_url'].value_counts()\n",
    "# if a race has a frequency > 1 then this race may represent an inconsistency between the race's attributes\n",
    "inconsistent_urls = values_count[values_count > 1]\n",
    "len(inconsistent_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position\n",
    "**TODO** Alcuni valori di position sono 0. Zero indica il primo classificato oppure può essere interpretato come una sorta di valore di default?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the notebook section on data distribution, the distribution of the feature _length_ has an anomalous shape. It seems to be a Gaussian distribution, but with a strange peak for very low values of length. This could be due, for example, the use of a different unit of measure to represent the distance (Km vs Metres).\n",
    "Perhaps some races have a length expressed in Kilometres rather than Metres, since the maximum for this column is 338000, the mean is 166776.180584 and the minimum is 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to identify the race events with a short length value. We initially set a threshold of 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = races[races['length'] <= 10000]\n",
    "temp['_url'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that there are some race events with a length < 10000 and most of them have a suffix of the url matching \"prologue\" or \"stage-1\". In fact, by searching information on the project domain, we discovered that the prologue is a short *individual time trial* that takes place at the start of a multi stage race. The prologue has typicalle a maximum length of 8 Km (according to UCI regulations) and it's used to determine the initial time gaps between the riders in the race stages. <br>\n",
    "\n",
    "Some multistage races have not a prologue but a *stage1* with a short (but >8Km) length or a massive start (not individual).\n",
    "[Stage1 vs Prologue](https://www.reddit.com/r/peloton/comments/4nt3yc/prologue_vs_stage_1/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics for prologue races\n",
    "unique_subset = races[races['_url'].str.contains(\"prologue\")][['_url', 'length']].drop_duplicates(subset=['_url'])\n",
    "unique_subset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation analysis\n",
    "**TODO** Normalizzazione prima della correlazione?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_races_data = races_data.select_dtypes(include=\"number\")\n",
    "numeric_races_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbn.scatterplot(data=races_data, x=\"points\", y=\"uci_points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this analysis we can see that the 'uci_points' and the 'points' are high correlated, so we can choose to maintain only one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see that there is a correlation between 'profile' and 'climb', in fact the profile of a race is a ranking of its difficulty and it is influenced by the climbs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclists DATASET\n",
    "**TODO** Inseriamo qui qualche statistica sul dataset dei ciclisti? oppure facciamo un file a parte? Visto che poi dobbiamo \"incrociare\" i dati dei due dataset può essere utile sapere cosa abbiamo anche in 'cyclists'. Qualcosa ho già fatto all'inizio, come \"esplorazione personale\". In caso posso inserire qui sotto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
